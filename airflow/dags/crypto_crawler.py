import requests
import pymysql
import os 
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from dotenv import load_dotenv
import time
from datetime import datetime, timedelta
from selenium_stealth import stealth

# âœ… .env íŒŒì¼ ë¡œë“œ (API í‚¤ ë³´ì•ˆ ì²˜ë¦¬)
load_dotenv("/opt/airflow/.env")

# âœ… MySQL ì—°ê²° ì„¤ì •
DB_CONFIG = {
    "host": os.getenv("DB_HOST"),
    "user": os.getenv("DB_USER"),
    "password": os.getenv("DB_PASSWORD"),
    "database": os.getenv("DB_NAME"),
    "port": int(os.getenv("DB_PORT")),
    "cursorclass": pymysql.cursors.DictCursor
}

# âœ… í—ˆìš©ëœ 10ê°œ ì½”ì¸ ë¦¬ìŠ¤íŠ¸ (MySQLì˜ coin_idì™€ ë§¤ì¹­)
ALLOWED_TICKERS = {
    "KRW-XRP": (1, "XRP"),
    "KRW-BTC": (2, "BTC"),
    "KRW-ETH": (3, "ETH"),
    "KRW-QTUM": (4, "QTUM"),
    "KRW-WAVES": (5, "WAVES"),
    "KRW-XEM": (6, "XEM"),
    "KRW-ETC": (7, "ETC"),
    "KRW-NEO": (8, "NEO"),
    "KRW-SNT": (9, "SNT"),
    "KRW-MTL": (10, "MTL")
}

# âœ… ScraperAPI ì„¤ì •
#SCRAPERAPI_KEY = os.getenv("SCRAPERAPI_KEY")
#proxy = f"http://scraperapi:{SCRAPERAPI_KEY}@proxy-server.scraperapi.com:8001"

# âœ… CryptoPanic API ì„¤ì •
API_KEY = os.getenv("CRYPTOPANIC_API_KEY")
API_URL = f"https://cryptopanic.com/api/v1/posts/?auth_token={API_KEY}"

# âœ… Selenium ë“œë¼ì´ë²„ ì„¤ì •
def get_driver():
    options = uc.ChromeOptions()
    #options.add_argument(f"--proxy-server={proxy}")
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")	
    options.add_argument("--disable-popup-blocking")
    options.add_argument("user-agent=Mozilla/5.0")
    
    driver = uc.Chrome(
    	options=options,
    	driver_executable_path="/opt/airflow/bin/chromedriver",
    	browser_executable_path="/opt/chrome/chrome"
    )

    stealth(driver,
    languages=["en-US", "en"],
    vendor="Google Inc.",
    platform="Win32",
    webgl_vendor="Intel Inc.",
    renderer="Intel Iris OpenGL Engine",
    fix_hairline=True,
    )

    return driver

# âœ… ë‚ ì§œ ë³€í™˜ í•¨ìˆ˜ (UTC â†’ KST)
def parse_datetime(time_str):
    try:
        if not time_str:
            return datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")
        if "T" in time_str and "Z" in time_str:
            dt = datetime.strptime(time_str, "%Y-%m-%dT%H:%M:%SZ") + timedelta(hours=9)
            return dt.strftime("%Y-%m-%d %H:%M:%S")
        return datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")
    except Exception as e:
        print(f"âŒ ë‚ ì§œ ë³€í™˜ ì˜¤ë¥˜: {e}")
        return datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")

# âœ… í‹°ì»¤ ë³€í™˜ & 10ê°œ ì½”ì¸ í•„í„°ë§
def get_coin_info(ticker):
    if not ticker.startswith("KRW-"):
        ticker = f"KRW-{ticker}"
    return ALLOWED_TICKERS.get(ticker, None)

# âœ… ì›ë³¸ ì£¼ì†Œ ë¦¬ë””ë ‰ì…˜ ì¶”ì  (JavaScript ê°•ì œ í´ë¦­ ë²„ì „)
def get_original_url_by_click(crypto_panic_url):
    driver = get_driver()
    try:
        driver.get(crypto_panic_url)

        # ğŸ” ì•„ì´ì½˜ ë§í¬ ìš”ì†Œ ëŒ€ê¸° (ì™¸ë¶€ ë§í¬ ë²„íŠ¼)
        icon = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.CSS_SELECTOR, "h1.post-title > a > .icon-link-external"))
        )
        
        current_tabs = driver.window_handles

        # âœ… ìë°”ìŠ¤í¬ë¦½íŠ¸ë¡œ ê°•ì œ í´ë¦­
        driver.execute_script("arguments[0].click();", icon)
        print("âœ… ì™¸ë¶€ ë§í¬ ì•„ì´ì½˜ í´ë¦­ (JS ì‹¤í–‰ ì™„ë£Œ)")
        
        # ìƒˆ íƒ­ì´ ì—´ë¦´ ë•Œê¹Œì§€ ëŒ€ê¸°
        WebDriverWait(driver, 10).until(
            lambda d: len(d.window_handles) > len(current_tabs)
        )

        # ìƒˆ íƒ­ìœ¼ë¡œ ì „í™˜
        new_tab = [tab for tab in driver.window_handles if tab not in current_tabs][0]
        driver.switch_to.window(new_tab)
        print("âœ… ìƒˆ íƒ­ìœ¼ë¡œ ì „í™˜ë¨")
        print(f"ğŸŒ í˜„ì¬ URL: {driver.current_url}")
        
        original_url = driver.current_url
        print(f"ğŸ”— ì‹¤ì œ JS í´ë¦­ìœ¼ë¡œ ì—´ë¦° ì›ë¬¸ ì£¼ì†Œ: {original_url}")
        return original_url

    except Exception as e:
        print(f"âŒ JS í´ë¦­ ì›ë¬¸ ë§í¬ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return crypto_panic_url

    finally:
        driver.quit()



# âœ… ë³¸ë¬¸ í¬ë¡¤ë§ í•¨ìˆ˜ (CryptoPanic ìš”ì•½ìš©)
def get_news_content_from_cryptopanic(crypto_panic_url):
    driver = get_driver()
    try:
        driver.get(crypto_panic_url)

        time.sleep(6)  # âœ… ë Œë”ë§ ê¸°ë‹¤ë¦¼

        article_text = driver.execute_script(
            "return document.querySelector('.description-body')?.innerText || '';"
        )

        if not article_text or len(article_text.strip()) < 10:
            print("âš ï¸ ë³¸ë¬¸ ë¹„ì–´ ìˆìŒ (innerText ë¶€ì¡±)")
            return None, None

        translated_text = GoogleTranslator(source="en", target="ko").translate(article_text[:5000])
        return article_text.strip(), translated_text

    except Exception as e:
        print(f"âŒ ë³¸ë¬¸ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        return None, None

    finally:
        driver.quit()

        
# âœ… íŠ¸ìœ„í„°/ìœ íŠœë¸Œ/ë ˆë”§ ì œì™¸
def is_excluded_source(source_domain):
    exclude_list = ["twitter.com", "youtube.com", "youtu.be", "reddit.com"]
    return any(ex in source_domain for ex in exclude_list)
        
# âœ… ë‰´ìŠ¤ í¬ë¡¤ë§ & ì €ì¥
news_data = []
news_coin_relations = []
filtered_articles = 0  
duplicate_news = 0  

try:
    conn = pymysql.connect(**DB_CONFIG)
    cursor = conn.cursor()

    response = requests.get(API_URL, headers={"User-Agent": "Mozilla/5.0"})
    data = response.json()
    if "results" not in data:
        print(f"API ì‘ë‹µì— 'results' í‚¤ê°€ ì—†ìŒ: {data}")
        exit()

    cursor.execute("SELECT source FROM news;")
    existing_sources = {row["source"] for row in cursor.fetchall()}

    for post in data["results"]:
        title_en = post["title"]
        title_ko = GoogleTranslator(source="en", target="ko").translate(title_en)
        crypto_panic_url = post["url"]
        source_domain = post.get("domain", "")
        newspaper = post.get("source", {}).get("title", "N/A")

        print("\nğŸ” ë‰´ìŠ¤ ê²€ì‚¬ ì‹œì‘")
        print(f"ğŸ“° ì œëª©: {title_en}")
        print(f"ğŸ”— ì¤‘ê³„ URL: {crypto_panic_url}")
        print(f"ğŸŒ ë„ë©”ì¸: {source_domain}")
        print(f"ğŸ›ï¸ ì‹ ë¬¸ì‚¬: {newspaper}")
        
        # âŒ ì œì™¸ ë„ë©”ì¸ ì°¨ë‹¨
        if is_excluded_source(source_domain):
            print("ğŸš« ì œì™¸ëœ ë„ë©”ì¸ (íŠ¸ìœ„í„°/ìœ íŠœë¸Œ ë“±)")
            continue
            
        # ì¤‘ë³µë‰´ìŠ¤
        original_url = get_original_url_by_click(crypto_panic_url)      
        if original_url in existing_sources:
            print("âš ï¸ ì´ë¯¸ ì €ì¥ëœ ë‰´ìŠ¤ (ì¤‘ë³µ)")
            duplicate_news += 1
            continue

        # âœ… ë³¸ë¬¸ í¬ë¡¤ë§
        content_en, content_ko = get_news_content_from_cryptopanic(crypto_panic_url)
        if not content_en:
            print("âš ï¸ ë³¸ë¬¸ ì—†ìŒ or í¬ë¡¤ë§ ì‹¤íŒ¨")
            continue	    
        else:
            print(f"âœ… ë³¸ë¬¸ í¬ë¡¤ë§ ì„±ê³µ ({len(content_en)}ì)")

        # âœ… 10ê°œ ì½”ì¸ë§Œ í•„í„°ë§ & ì¤‘ë³µ ì œê±°
        related_coins = list(set(get_coin_info(coin["code"]) for coin in post.get("currencies", []) if "code" in coin))
        related_coins = [coin for coin in related_coins if coin is not None]

        related_coin_ids = list(set(coin[0] for coin in related_coins))  # ì½”ì¸ ID ì¤‘ë³µ ì œê±°
        related_tickers = list(set(coin[1] for coin in related_coins))  # ì½”ì¸ í‹°ì»¤ ì¤‘ë³µ ì œê±°

        if not related_coin_ids:
            print(f"âš ï¸ ê´€ë ¨ ì½”ì¸ ì—†ìŒ â†’ ì €ì¥ ì œì™¸ë¨ (ì½”ì¸ ëª©ë¡: {[coin.get('code') for coin in post.get('currencies', [])]})")
            filtered_articles += 1
            continue
        else:
            print(f"âœ… ê´€ë ¨ ì½”ì¸ ìˆìŒ â†’ IDs: {related_coin_ids}, Tickers: {related_tickers}")
            
        #ë‚ ì§œ íŒŒì‹±
        news_datetime = parse_datetime(post.get("published_at", ""))
        
        # âœ… ë‰´ìŠ¤ ì €ì¥ (ì¤‘ë³µ ì—…ë°ì´íŠ¸)
        print("âœ… ì´ ë‰´ìŠ¤ëŠ” DBì— ì €ì¥ë©ë‹ˆë‹¤.")        
        insert_news_query = """
        INSERT INTO news (title, title_en, content, content_en, newspaper, source, uploadtime)
        VALUES (%s, %s, %s, %s, %s, %s, %s)
        ON DUPLICATE KEY UPDATE title=VALUES(title), content=VALUES(content), uploadtime=VALUES(uploadtime);
        """
        cursor.execute(insert_news_query, (title_ko, title_en, content_ko, content_en, newspaper, original_url, news_datetime))
        conn.commit()

        # âœ… ì €ì¥ëœ ë‰´ìŠ¤ ID ê°€ì ¸ì˜¤ê¸°
        cursor.execute("SELECT news_id FROM news WHERE source = %s;", (original_url,))
        news_row = cursor.fetchone()
        news_id = news_row["news_id"] if news_row else None

        if news_id:
            insert_relation_query = "INSERT IGNORE INTO news_coin_relation (news_id, coin_id) VALUES (%s, %s)"
            cursor.executemany(insert_relation_query, [(news_id, coin_id) for coin_id in related_coin_ids])
            conn.commit()

        print("\n ====================== ")
        print(f" ğŸ“° ë‰´ìŠ¤ ì œëª© (í•œê¸€): {title_ko}")
        print(f" ğŸ“° ë‰´ìŠ¤ ì œëª© (ì˜ì–´): {title_en}")
        print(f" ğŸ“„ ë‰´ìŠ¤ ë³¸ë¬¸ (í•œê¸€ ë²ˆì—­):\n{content_ko[:500]}...")
        print(f" ğŸ“„ ë‰´ìŠ¤ ë³¸ë¬¸ (ì›ë³¸ ì˜ì–´):\n{content_en[:500]}...")
        print(f" ğŸ›ï¸ ì‹ ë¬¸ì‚¬: {newspaper}")
        print(f" ğŸ”— ê¸°ì‚¬ ì†ŒìŠ¤: {original_url}")
        print(f" ğŸ•’ ì—…ë¡œë“œ ì‹œê°„ (KST): {news_datetime}")
        print(f" ğŸ’° ê´€ë ¨ ì½”ì¸ ID: {related_coin_ids}")
        print(f" ğŸ’° ê´€ë ¨ ì½”ì¸ í‹°ì»¤: {related_tickers}")
        print(" ====================== \n")

    cursor.close()
    conn.close()

except Exception as e:
    print(f"í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

print(f"ğŸ“Œ ì½”ì¸ì´ ì—†ëŠ” ê¸°ì‚¬ {filtered_articles}ê°œëŠ” ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.") 
print(f"âš ï¸ ì¤‘ë³µëœ ê¸°ì‚¬ {duplicate_news}ê°œëŠ” ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
